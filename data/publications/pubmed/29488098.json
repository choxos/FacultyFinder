{
  "pmid": "29488098",
  "uid": "29488098",
  "title": "i-Assess: Evaluating the impact of electronic data capture for OSCE.",
  "abstract": "INTRODUCTION: Tablet-based assessments offer benefits over scannable-paper assessments; however, there is little known about the impact to the variability of assessment scores. METHODS: Two studies were conducted to evaluate changes in rating technology. Rating modality (paper vs tablets) was manipulated between candidates (Study 1) and within candidates (Study 2). Average scores were analyzed using repeated measures ANOVA, Cronbach's alpha and generalizability theory. Post-hoc analyses included a Rasch analysis and McDonald's omega. RESULTS: Study 1 revealed a main effect of modality (F (1,152) = 25.06, p < 0.01). Average tablet-based scores were higher, (3.39/5, 95% CI = 3.28 to 3.51), compared with average scan-sheet scores (3.00/5, 95% CI = 2.90 to 3.11). Study 2 also revealed a main effect of modality (F (1, 88) = 15.64, p < 0.01), however, the difference was reduced to 2% with higher scan-sheet scores (3.36, 95% CI = 3.30 to 3.42) compared with tablet scores (3.27, 95% CI = 3.21 to 3.33). Internal consistency (alpha and omega) remained high (>0.8) and inter-station reliability remained constant (0.3). Rasch analyses showed no relationship between station difficulty and rating modality. DISCUSSION: Analyses of average scores may be misleading without an understanding of internal consistency and overall reliability of scores. Although updating to tablet-based forms did not result in systematic variations in scores, routine analyses ensured accurate interpretation of the variability of assessment scores. CONCLUSION: This study demonstrates the importance of ongoing program evaluation and data analysis.",
  "authors": [
    {
      "last_name": "Monteiro",
      "fore_name": "Sandra",
      "initials": "S",
      "name": "Sandra Monteiro",
      "affiliations": [
        "Department of Health Research Methods, Evidence and Impact, McMaster University, Hamilton, Canada. monteisd@mcmaster.ca.",
        "Touchstone Institute, Toronto, Canada. monteisd@mcmaster.ca."
      ],
      "orcid": "0000-0001-8723-5942"
    },
    {
      "last_name": "Sibbald",
      "fore_name": "Debra",
      "initials": "D",
      "name": "Debra Sibbald",
      "affiliations": [
        "Touchstone Institute, Toronto, Canada.",
        "Department of Pharmacy, University of Toronto, Toronto, Canada."
      ]
    },
    {
      "last_name": "Coetzee",
      "fore_name": "Karen",
      "initials": "K",
      "name": "Karen Coetzee",
      "affiliations": [
        "Touchstone Institute, Toronto, Canada."
      ]
    }
  ],
  "journal": {
    "title": "Perspectives on medical education",
    "iso_abbreviation": "Perspect Med Educ",
    "issn": "2212-2761",
    "issn_type": "Print",
    "volume": "7",
    "issue": "2",
    "pub_year": "2018",
    "pub_month": "Apr"
  },
  "start_page": "110",
  "end_page": "119",
  "pages": "110-119",
  "language": "eng",
  "publication_types": [
    "Journal Article",
    "Research Support, Non-U.S. Gov't"
  ],
  "keywords": [
    "Analysis of Variance",
    "Computers, Handheld",
    "Educational Measurement",
    "Equipment Design",
    "Humans",
    "Psychometrics",
    "Qualitative Research",
    "Reproducibility of Results",
    "Test Taking Skills"
  ],
  "article_ids": {
    "pubmed": "29488098",
    "pmc": "PMC5889381",
    "doi": "10.1007/s40037-018-0410-4",
    "pii": "10.1007/s40037-018-0410-4"
  },
  "doi": "10.1007/s40037-018-0410-4",
  "pmc_id": "PMC5889381",
  "dates": {
    "completed": "2019-07-15",
    "revised": "2024-03-14"
  },
  "chemicals": [],
  "grants": [],
  "search_metadata": {
    "search_type": "current_affiliation",
    "retrieved_date": "2025-07-30T14:45:26.043128",
    "pmid": "29488098"
  }
}