#!/usr/bin/env python3
"""
Parse Medline format files generated by esearch/efetch
Converts to JSON/CSV format for database import
"""

import os
import json
import csv
import sys
import re
from datetime import datetime
from typing import Dict, List, Optional

class MedlineParser:
    """Parser for NCBI Medline format files"""
    
    def __init__(self):
        self.current_record = {}
        self.publications = []
    
    def parse_file(self, file_path: str, faculty_name: str = None) -> List[Dict]:
        """Parse a single medline file"""
        
        print(f"üìÑ Parsing {file_path}...")
        
        if not os.path.exists(file_path):
            print(f"‚ùå File not found: {file_path}")
            return []
        
        # Extract faculty name from filename if not provided
        if not faculty_name:
            filename = os.path.basename(file_path)
            faculty_name = filename.replace("_publications.txt", "").replace("_", " ")
        
        publications = []
        current_record = {}
        
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                for line in f:
                    line = line.strip()
                    
                    if not line:
                        # Empty line - end of record
                        if current_record:
                            pub_data = self._process_record(current_record, faculty_name)
                            if pub_data:
                                publications.append(pub_data)
                            current_record = {}
                        continue
                    
                    # Parse field
                    if '- ' in line:
                        field, value = line.split('- ', 1)
                        field = field.strip()
                        value = value.strip()
                        
                        if field in current_record:
                            # Multiple values for same field
                            if isinstance(current_record[field], list):
                                current_record[field].append(value)
                            else:
                                current_record[field] = [current_record[field], value]
                        else:
                            current_record[field] = value
                
                # Process final record
                if current_record:
                    pub_data = self._process_record(current_record, faculty_name)
                    if pub_data:
                        publications.append(pub_data)
        
        except Exception as e:
            print(f"‚ùå Error parsing {file_path}: {str(e)}")
            return []
        
        print(f"   ‚úÖ Parsed {len(publications)} publications")
        return publications
    
    def _process_record(self, record: Dict, faculty_name: str) -> Optional[Dict]:
        """Process a single publication record"""
        
        try:
            # Extract PMID
            pmid = record.get('PMID', '')
            if not pmid:
                return None
            
            # Extract title
            title = record.get('TI', '')
            if isinstance(title, list):
                title = ' '.join(title)
            
            # Extract abstract
            abstract = record.get('AB', '')
            if isinstance(abstract, list):
                abstract = ' '.join(abstract)
            
            # Extract authors
            authors = []
            au_fields = record.get('AU', [])
            if isinstance(au_fields, str):
                au_fields = [au_fields]
            elif au_fields:
                authors = au_fields
            
            authors_str = "; ".join(authors) if authors else ""
            
            # Extract journal
            journal_name = record.get('JT', '') or record.get('TA', '')
            
            # Extract publication date
            pub_date = None
            pub_year = None
            
            # Try different date fields
            date_fields = ['DP', 'DA', 'DEP']
            for date_field in date_fields:
                if date_field in record:
                    date_str = record[date_field]
                    if isinstance(date_str, list):
                        date_str = date_str[0]
                    
                    # Extract year
                    year_match = re.search(r'(\d{4})', date_str)
                    if year_match:
                        pub_year = int(year_match.group(1))
                        
                        # Try to extract full date
                        date_match = re.search(r'(\d{4})/(\d{1,2})/(\d{1,2})', date_str)
                        if date_match:
                            year, month, day = date_match.groups()
                            pub_date = f"{year}-{month.zfill(2)}-{day.zfill(2)}"
                        elif re.search(r'(\d{4})/(\d{1,2})', date_str):
                            date_match = re.search(r'(\d{4})/(\d{1,2})', date_str)
                            year, month = date_match.groups()
                            pub_date = f"{year}-{month.zfill(2)}-01"
                        else:
                            pub_date = f"{pub_year}-01-01"
                    break
            
            # Extract DOI
            doi = ""
            doi_fields = ['LID', 'AID']
            for doi_field in doi_fields:
                if doi_field in record:
                    doi_values = record[doi_field]
                    if isinstance(doi_values, str):
                        doi_values = [doi_values]
                    
                    for doi_value in doi_values:
                        if 'doi' in doi_value.lower():
                            # Extract DOI from string like "10.1234/example [doi]"
                            doi_match = re.search(r'(10\.\d+/[^\s\[\]]+)', doi_value)
                            if doi_match:
                                doi = doi_match.group(1)
                                break
                    if doi:
                        break
            
            # Extract volume, issue, pages
            volume = record.get('VI', '')
            issue = record.get('IP', '')
            pages = record.get('PG', '')
            
            # Create publication data
            publication_data = {
                'pmid': pmid,
                'doi': doi,
                'title': title,
                'abstract': abstract,
                'authors': authors_str,
                'journal_name': journal_name,
                'publication_date': pub_date,
                'publication_year': pub_year,
                'volume': volume,
                'issue': issue,
                'pages': pages,
                'faculty_name': faculty_name,
                'created_at': datetime.now().isoformat()
            }
            
            return publication_data
            
        except Exception as e:
            print(f"      Warning: Failed to process record: {str(e)}")
            return None
    
    def parse_directory(self, directory_path: str, output_dir: str = "parsed_publications") -> Dict:
        """Parse all medline files in a directory"""
        
        print(f"üìÅ Parsing medline files from: {directory_path}")
        
        if not os.path.exists(directory_path):
            print(f"‚ùå Directory not found: {directory_path}")
            return {}
        
        os.makedirs(output_dir, exist_ok=True)
        
        all_publications = []
        faculty_results = []
        
        # Find all .txt files
        txt_files = [f for f in os.listdir(directory_path) if f.endswith('.txt')]
        
        if not txt_files:
            print(f"‚ùå No .txt files found in {directory_path}")
            return {}
        
        print(f"Found {len(txt_files)} files to parse")
        
        for filename in txt_files:
            file_path = os.path.join(directory_path, filename)
            
            # Extract faculty name from filename
            faculty_name = filename.replace("_publications.txt", "").replace("_", " ")
            
            # Parse file
            publications = self.parse_file(file_path, faculty_name)
            
            if publications:
                # Save individual faculty file
                faculty_output = os.path.join(output_dir, f"{faculty_name.replace(' ', '_')}_parsed.json")
                with open(faculty_output, 'w') as f:
                    json.dump({
                        'faculty_name': faculty_name,
                        'publication_count': len(publications),
                        'publications': publications
                    }, f, indent=2)
                
                # Add to combined results
                all_publications.extend(publications)
                faculty_results.append({
                    'name': faculty_name,
                    'publication_count': len(publications),
                    'source_file': filename
                })
                
                print(f"   üìù Saved: {faculty_output}")
        
        # Save combined results
        combined_json = os.path.join(output_dir, "all_publications.json")
        with open(combined_json, 'w') as f:
            json.dump(all_publications, f, indent=2)
        
        # Save CSV
        combined_csv = os.path.join(output_dir, "all_publications.csv")
        if all_publications:
            with open(combined_csv, 'w', newline='', encoding='utf-8') as f:
                writer = csv.DictWriter(f, fieldnames=all_publications[0].keys())
                writer.writeheader()
                writer.writerows(all_publications)
        
        # Save summary
        summary = {
            'parse_date': datetime.now().isoformat(),
            'source_directory': directory_path,
            'total_files': len(txt_files),
            'faculty_with_publications': len([r for r in faculty_results if r['publication_count'] > 0]),
            'total_publications': len(all_publications),
            'faculty_results': faculty_results
        }
        
        summary_file = os.path.join(output_dir, "parse_summary.json")
        with open(summary_file, 'w') as f:
            json.dump(summary, f, indent=2)
        
        print(f"\nüéâ Parsing Complete!")
        print(f"   üìä Summary: {summary['faculty_with_publications']}/{summary['total_files']} files with publications")
        print(f"   üìö Total publications: {summary['total_publications']}")
        print(f"   üìÅ Output directory: {output_dir}/")
        print(f"   üìã Combined JSON: {combined_json}")
        print(f"   üìã Combined CSV: {combined_csv}")
        
        return summary

def main():
    """Main function for parsing medline files"""
    
    print("üìñ Medline File Parser")
    print("=" * 40)
    print("Converts esearch/efetch output to importable format\n")
    
    if len(sys.argv) < 2:
        print("Usage: python3 parse_medline_files.py <directory_or_file>")
        print("\nExamples:")
        print("  python3 parse_medline_files.py pubmed_data/")
        print("  python3 parse_medline_files.py pubmed_data/Gordon_Guyatt_publications.txt")
        sys.exit(1)
    
    input_path = sys.argv[1]
    parser = MedlineParser()
    
    if os.path.isdir(input_path):
        # Parse directory
        summary = parser.parse_directory(input_path)
        
        if summary.get('total_publications', 0) > 0:
            print("\nüöÄ Next Steps:")
            print("1. Transfer to VPS: scp -r parsed_publications/ user@vps:/var/www/ff/")
            print("2. Import to database: python3 import_pubmed_data.py parsed_publications/")
        
    elif os.path.isfile(input_path):
        # Parse single file
        publications = parser.parse_file(input_path)
        
        if publications:
            # Save single file results
            output_file = "single_publication_parse.json"
            with open(output_file, 'w') as f:
                json.dump(publications, f, indent=2)
            
            print(f"‚úÖ Parsed {len(publications)} publications")
            print(f"üìÅ Saved to: {output_file}")
        
    else:
        print(f"‚ùå Path not found: {input_path}")

if __name__ == "__main__":
    main() 